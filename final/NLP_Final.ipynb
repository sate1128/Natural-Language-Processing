{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Title Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "# import gensim\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import pprint as pp\n",
    "import re\n",
    "from scipy import spatial\n",
    "from TranslationTool.langconv import *\n",
    "from hanziconv import HanziConv\n",
    "from pycorenlp import StanfordCoreNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Models\n",
    "**Don't run this block twice!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading():\n",
    "    # load stopwords\n",
    "    with open(\"stopwords.txt\", encoding='utf8') as fp:\n",
    "        dat = fp.read()\n",
    "    global stop_words\n",
    "    stop_words = dat.split('\\n')\n",
    "    del stop_words[-1]\n",
    "\n",
    "    # load word2vec model\n",
    "    global model\n",
    "    # model = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary = True, unicode_errors = 'ignore')\n",
    "    model = pickle.load(open(\"model.pkl\", \"rb\"))\n",
    "\n",
    "    # load idf list\n",
    "    global idf\n",
    "    with open('idf.txt', encoding='utf8') as fp:\n",
    "        dat = fp.read()\n",
    "    lines = dat.split('\\n')\n",
    "    del lines[-1]\n",
    "    idf = [(l.split()[0], float(l.split()[1])) for l in lines]\n",
    "    \n",
    "    # connect to StanfordCoreNLP\n",
    "    global nlp\n",
    "    nlp = StanfordCoreNLP('http://140.113.193.76:9000')\n",
    "#     nlp = StanfordCoreNLP('http://140.113.208.179:8002')\n",
    "    \n",
    "    # feature database of evaluation part\n",
    "    global f1_dict, mv_list_vec, f3_dict\n",
    "    f1_dict = pickle.load(open(\"f1_dict.pkl\", \"rb\"))\n",
    "    mv_list_vec = pickle.load(open(\"f2_dict.pkl\", \"rb\"))\n",
    "    f3_dict = pickle.load(open(\"f3_dict.pkl\", \"rb\"))\n",
    "    \n",
    "    return\n",
    "\n",
    "# global variable with empty value as initialization\n",
    "model = None\n",
    "# model_path = \"cna_asbc_cbow_d300_w10_n10_hs0_i15.vectors.bin\"\n",
    "nlp = None\n",
    "\n",
    "stop_words = []\n",
    "idf = []\n",
    "\n",
    "f1_dict = {}\n",
    "mv_list_vec = []\n",
    "f3_dict = {}\n",
    "\n",
    "# loading\n",
    "loading()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading File and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_contain_chinese(check_str):\n",
    "    for ch in check_str:\n",
    "        if u'\\u4e00' <= ch <= u'\\u9fff':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def readFile(path):\n",
    "    \n",
    "    segs = []\n",
    "    \n",
    "    with open(path, 'r', encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            if check_contain_chinese(line):\n",
    "                line = re.sub(r'[^\\w]','',line) \n",
    "                seg_list = jieba.cut(line)\n",
    "                if seg_list:\n",
    "                    for s in seg_list:\n",
    "                        if check_contain_chinese(s):\n",
    "                            segs.append(s)\n",
    "    \n",
    "#     with open(path, encoding='utf8') as fp:\n",
    "#         dat = fp.read()\n",
    "    \n",
    "#     lines = dat.split('\\n')\n",
    "#     del lines[-1]\n",
    "    \n",
    "#     # segmentation\n",
    "#     segs = []\n",
    "#     for line in lines:\n",
    "#         tmp = [Converter('zh-hant').convert(w) for w in line.split('/')[:-1]]\n",
    "#         segs.extend(tmp)\n",
    "#         # jieba.cut(line, cut_all=False)\n",
    "    \n",
    "    return segs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfGen(segs):\n",
    "    \n",
    "    # compute tf (word count and frequency)\n",
    "    words, counts = np.unique(segs, return_counts=True) # default: axis=None\n",
    "    frequency = counts / len(segs)\n",
    "    tf = list(zip(words, frequency))\n",
    "    tf = sorted(tf, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return tf\n",
    "\n",
    "def tfidfGen(tf):\n",
    "    \n",
    "    idf_dict = {word: value for word, value in idf}\n",
    "    \n",
    "    words = []\n",
    "    values = []\n",
    "    for word, value in tf:\n",
    "        words.append(word)\n",
    "        if word in idf_dict:\n",
    "            values.append(value * idf_dict[word])\n",
    "        else:\n",
    "            values.append(value * 8)\n",
    "\n",
    "    tfidf = list(zip(words, values))\n",
    "    tfidf = sorted(tfidf, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keywordExt(tfidf):\n",
    "    \n",
    "    global model, stop_words, num_keywords\n",
    "    \n",
    "    i = 0\n",
    "    word_ls = []\n",
    "    for word, count in tfidf:\n",
    "        if i == num_keywords:\n",
    "            break\n",
    "        if word in stop_words:\n",
    "            continue\n",
    "        if word not in model:\n",
    "            continue\n",
    "        word_ls.append(word)\n",
    "        i += 1\n",
    "    \n",
    "    return word_ls\n",
    "\n",
    "def keywordSel(word_ls):\n",
    "    \n",
    "    # remove NR\n",
    "    global nlp, stop_words\n",
    "    \n",
    "    new_word_ls = []\n",
    "    for word in word_ls:\n",
    "        \n",
    "        if len(word) < 2 or len(word) > 3:\n",
    "            continue\n",
    "        \n",
    "        flag = False\n",
    "        for w in stop_words:\n",
    "            if w in word:\n",
    "                flag = True\n",
    "        if flag:\n",
    "            continue\n",
    "        \n",
    "        output = nlp.annotate(word, properties={\n",
    "            'annotators': 'pos',\n",
    "            'outputFormat': 'json'\n",
    "        })\n",
    "        pos = output['sentences'][0]['tokens'][0]['pos']\n",
    "        if pos != 'NR':\n",
    "            new_word_ls.append((word, pos))\n",
    "            \n",
    "    return new_word_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genre Classification (feature base, which is not used now)\n",
    " - feature generation\n",
    " - SVM classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variable with predefined value\n",
    "num_keywords = 40\n",
    "\n",
    "def featureGen(word_ls):\n",
    "    \n",
    "    # add feature from word2vec\n",
    "    \n",
    "    feature = list(np.zeros(300))\n",
    "    for word in word_ls:\n",
    "        feature += model.word_vec(word)\n",
    "    \n",
    "    return feature\n",
    "\n",
    "def featureGen2(tfidf):\n",
    "    \n",
    "    global word_ls\n",
    "    \n",
    "    tfidf_dict = {word: value for word, value in tfidf}\n",
    "    feature = []\n",
    "    for word in word_ls:\n",
    "        if word in tfidf_dict:\n",
    "            feature.append(tfidf_dict[word])\n",
    "        else:\n",
    "            feature.append(0)\n",
    "    \n",
    "    \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genre Classification\n",
    " - rule base\n",
    " - with corresponding to keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variable with predefined value\n",
    "# keyword definition: [[keyword, ...], [key alphabet, ...]]\n",
    "script_keyword = {\n",
    "    'action': [['特工', '殺手'], ['警', '賭']],\n",
    "    'comedy': [['嘿咻'], ['裸', '妓', '屁']],\n",
    "    'crime': [['暴力', '受害者', '罪犯', '犯罪'], ['毒']],\n",
    "    'drama': [[], []],\n",
    "#     'fantasy': [[], ['獸']],\n",
    "    'super': [['征服', '變身', '換裝', '英雄', '超人', '拯救', '超能力'], []],\n",
    "    'horror': [[], ['怪', '屍', '鬼']],\n",
    "    'romance': [[], ['愛', '戀']],\n",
    "    'sci_fi': [['星球', '星際', '太空', '時空', '星艦', '宇宙'], []],\n",
    "    'war': [['坦克', '地雷'], ['軍', '戰']]\n",
    "}\n",
    "\n",
    "def ruleBaseClassify(word_ls):\n",
    "    # print(word_ls)\n",
    "    \n",
    "    for word in word_ls:\n",
    "        for key, content in script_keyword.items():\n",
    "            if word in content[0]:\n",
    "                return key\n",
    "    \n",
    "    for word in word_ls:\n",
    "        for key, content in script_keyword.items():\n",
    "            for sw in content[1]:\n",
    "                if sw in word:\n",
    "                    return key\n",
    "    \n",
    "#     for key, content in script_keyword.items():\n",
    "#         if content[0] == []:\n",
    "#             continue\n",
    "#         for sw in content[0]:\n",
    "#             if sw in word_ls:\n",
    "#                 return key\n",
    "    \n",
    "#     word_ls_str = ''.join(word_ls)\n",
    "#     for key, content in script_keyword.items():\n",
    "#         if content[1] == []:\n",
    "#             continue\n",
    "#         for sw in content[1]:\n",
    "#             if sw in word_ls_str:\n",
    "#                 return key\n",
    "    \n",
    "    return 'drama'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title Candidate Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variable with predefined value\n",
    "# rule definition: [POS, SPECIAL_WORD, ReverseOrNot]\n",
    "special_rule = {\n",
    "    'action': [['NN', '玩命', True], ['NN', '啟動', False], ['NN', '神鬼', True], ['NN', '遊戲', False]],\n",
    "    'comedy': [['NN', '行不行', False]],\n",
    "    'crime': [['NN', '檔案', False], ['NN', '風暴', False], ['NN', '風雲', False]],\n",
    "    'drama': [['NN', '神鬼', True], ['NN', '佚事', False]],\n",
    "#     'fantasy': [['NN', '神鬼', True]],\n",
    "    'super': [['NN', '聯盟', False]],\n",
    "    'horror': [['NN', '絕命', True], ['NN', '失控', True], ['VV', '鬼', True]],\n",
    "    'romance': [['NN', '真愛', True]],\n",
    "    'sci_fi': [['NN', '星際', True]],\n",
    "    'war': [['NN', '重生', False], ['NN', '救援', False]]\n",
    "}\n",
    "\n",
    "def block(s1, s2):\n",
    "    \n",
    "    # too similar\n",
    "    if s1 in model and s2 in model:\n",
    "        if model.wv.similarity(s1, s2) > 0.5:\n",
    "            # print('Too similar: %s, %s' %(s1, s2))\n",
    "            return True\n",
    "    \n",
    "    # contain the same alphabet\n",
    "    for ele in s1:\n",
    "        if ele in s2:\n",
    "            # print('Contain the same alphanet: %s, %s' %(s1, s2))\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "def titleCanGen(genre, word_pos_ls):\n",
    "    \n",
    "    global special_rule\n",
    "    \n",
    "    pos_dict = {}\n",
    "    for word, pos in word_pos_ls:\n",
    "        try:\n",
    "            pos_dict[pos].append(word)\n",
    "        except:\n",
    "            pos_dict[pos] = [word]\n",
    "    \n",
    "    candidates = []\n",
    "    \n",
    "    for rule in special_rule[genre]:\n",
    "        pos = rule[0]\n",
    "        for word in pos_dict[pos]:\n",
    "            if block(rule[1], word):\n",
    "                continue\n",
    "            if '之' in word:\n",
    "                candidates.append(rule[1]+word)\n",
    "            elif rule[2]:\n",
    "                candidates.append(rule[1]+word)\n",
    "            else:\n",
    "                candidates.append(word+rule[1])\n",
    "                \n",
    "    \n",
    "#     if genre is \"drama\":\n",
    "#          for word1 in pos_dict['NN']:\n",
    "#                 for word2 in pos_dict['NN']:\n",
    "#                     if block(word1, word2):\n",
    "#                         continue\n",
    "#                     candidates.append(word1+word2)\n",
    "    \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variable with predefined value\n",
    "special_word = [HanziConv.toSimplified(rule[1]) for key, content in special_rule.items() for rule in content]\n",
    "pos_simpify_dic = {'NN': 'N', 'NR': 'N', 'NT': 'N', 'VE': 'V', 'VV': 'V'}\n",
    "\n",
    "############################## parse.py ##############################\n",
    "\n",
    "def Simpify(pos):\n",
    "    global pos_simpify_dic\n",
    "    if pos in pos_simpify_dic.keys():\n",
    "        return pos_simpify_dic[pos]\n",
    "    return pos\n",
    "\n",
    "def Parse_String(mvname):\n",
    "    parse_results = []\n",
    "    # convert to simple chinese\n",
    "    text = HanziConv.toSimplified(mvname)\n",
    "    # parse by core nlp\n",
    "    global nlp\n",
    "    output = nlp.annotate(text, properties={'annotators': 'tokenize, ssplit, pos', 'outputFormat': 'json'})\n",
    "    parse_results.append(output)\n",
    "    return parse_results\n",
    "\n",
    "def Get_Parse_Result(parse_results):\n",
    "    # print(parse_results[0]['sentences'][0]['parse'])\n",
    "    l = []\n",
    "    for i in range(len(parse_results)):\n",
    "        for word in parse_results[i]['sentences'][0]['tokens']:\n",
    "            global special_word\n",
    "            if word['word'] in special_word:\n",
    "                l.append((word['word'], 'N'))\n",
    "            else:\n",
    "                l.append((word['word'], Simpify(word['pos'])))\n",
    "    return l\n",
    "\n",
    "def POStag(name):\n",
    "    parse_results = Parse_String(name)\n",
    "    l = Get_Parse_Result(parse_results)\n",
    "    return l\n",
    "\n",
    "############################## feature2.py ##############################\n",
    "\n",
    "def cosine(v1, v2):\n",
    "    res = 1 - spatial.distance.cosine(v1, v2)\n",
    "    return res\n",
    "\n",
    "def Create_mv_vector(mv_name):\n",
    "    # logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    # model = models.Word2Vec.load('med250.model.bin')\n",
    "    global model\n",
    "    \n",
    "    sum_vec = [0] * 250\n",
    "    for word in mv_name:\n",
    "        try:\n",
    "            v = model.wv[word]\n",
    "            sum_vec = sum_vec + v\n",
    "        except KeyError:\n",
    "            sum_vec = sum_vec\n",
    "    \n",
    "    return sum_vec\n",
    "\n",
    "def Most_similar(mv_name):\n",
    "    mv_name = [HanziConv.toTraditional(x) for x in mv_name]\n",
    "    mv_vec = Create_mv_vector(mv_name)\n",
    "\n",
    "    # caculate mv_name_vector\n",
    "    global mv_list_vec\n",
    "    # mv_list_vec = pickle.load(open(\"f2_dict.pkl\", \"rb\"))\n",
    "    \n",
    "    # Similarity with those movies\n",
    "    cosine_list = []\n",
    "    for mv in mv_list_vec:\n",
    "        cosine_list.append(cosine(mv_vec, mv))\n",
    "        # print(cosine(mv_vec, mv))\n",
    "    return max(cosine_list)\n",
    "\n",
    "############################## main.py ##############################\n",
    "\n",
    "def evaluation(mv_name):\n",
    "\n",
    "    # print(mv_name)\n",
    "    mv_name = HanziConv.toSimplified(mv_name)\n",
    "    \n",
    "    global f1_dict, f3_dict, model\n",
    "    \n",
    "    # POS tag\n",
    "    parse_result = POStag(mv_name)\n",
    "    # print(parse_result)\n",
    "\n",
    "    # f1 score\n",
    "    mv_words = [x[0] for x in parse_result]\n",
    "    pos_form = [x[1] for x in parse_result]\n",
    "    pos_form = tuple(pos_form)\n",
    "    \n",
    "    if pos_form in f1_dict:\n",
    "        f1 = f1_dict[pos_form]\n",
    "    else:\n",
    "        f1 = 0\n",
    "\n",
    "    # f2 score\n",
    "    f2 = Most_similar(mv_words)\n",
    "    if np.isnan(f2):\n",
    "        f2 = 0\n",
    "\n",
    "    # f3 score\n",
    "    # words = [x[0] for x in parse_result]\n",
    "    f3 = 0\n",
    "    for word in mv_words:\n",
    "        if word in f3_dict:\n",
    "            f3 = f3 + 0.2 + f3_dict[word]\n",
    "        else:\n",
    "            f3 = 0\n",
    "\n",
    "    # print(\"f1: %f, f2: %f, f3: %f\" %(f1, f2, f3))\n",
    "    score = f1 + f2 + f3\n",
    "    # print(\"score = \", score)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title Generation\n",
    " - main process of title generation\n",
    " - input: a file path\n",
    " - output: a sorted title list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titleGen(path):\n",
    "    \n",
    "    # read file\n",
    "    segs = readFile(path)\n",
    "    \n",
    "    # tfidf\n",
    "    tf = tfGen(segs)\n",
    "    tfidf = tfidfGen(tf)\n",
    "\n",
    "    # keyword\n",
    "    word_ls = keywordExt(tfidf)\n",
    "    word_pos_ls = keywordSel(word_ls)\n",
    "    word_ls = [word for word, pos in word_pos_ls]\n",
    "#     pp.pprint(word_ls)\n",
    "\n",
    "    # get genre\n",
    "    genre = ruleBaseClassify(word_ls)\n",
    "#     print(\"%-10s\" %genre, end='')\n",
    "\n",
    "    # title candidate generation\n",
    "    title_candidates = titleCanGen(genre, word_pos_ls)\n",
    "#     pp.pprint(title_candidates)\n",
    "\n",
    "    # evaluation\n",
    "    title_score = [(title, evaluation(title)) for title in title_candidates]\n",
    "    title_score = sorted(title_score, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return title_score, genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title Selection\n",
    "Give some random probability when choosing the final title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titleSel(title_score, genre):\n",
    "    \n",
    "    global special_rule\n",
    "    \n",
    "    lottery = []\n",
    "    \n",
    "    for rule in special_rule[genre]:\n",
    "        for i, (title, score) in enumerate(title_score):\n",
    "            if i > 10:\n",
    "                break\n",
    "            if rule[1] in title:\n",
    "                lottery.append(i)\n",
    "                break\n",
    "    \n",
    "    rand = np.random.choice(len(lottery))\n",
    "    \n",
    "    return lottery[rand]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 Main Process\n",
    "Put all the testing script file in one folder, and then find the best title for each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python35\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if sys.path[0] == '':\n",
      "c:\\python35\\lib\\site-packages\\ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "c:\\python35\\lib\\site-packages\\scipy\\spatial\\distance.py:505: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n",
      "c:\\python35\\lib\\site-packages\\scipy\\spatial\\distance.py:505: RuntimeWarning: invalid value encountered in true_divide\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drama     1.srt                                             黑道佚事      0.910647  0    \n",
      "romance   2.srt                                             真愛電影      0.951503  0    \n",
      "drama     3.srt                                             乙班佚事      0.780227  10   \n"
     ]
    }
   ],
   "source": [
    "# folder path\n",
    "folder = \"input\"\n",
    "files = os.listdir(folder)\n",
    "output_ls = []\n",
    "\n",
    "for file in files:\n",
    "    path = folder + '/' + file\n",
    "    title_score, genre = titleGen(path)\n",
    "    idx = titleSel(title_score, genre)\n",
    "    print(\"%-10s%-50s%-10s%-10f%-5d\" %(genre, file, title_score[idx][0], title_score[idx][1], idx))\n",
    "    output_ls.append(file.replace('.srt', '')+'\\t'+title_score[idx][0])\n",
    "\n",
    "filename = \"task1_group7.txt\"\n",
    "with open(filename, 'w', encoding=\"utf8\") as fp:\n",
    "    fp.write('\\n'.join(output_ls)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 Main Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python35\\lib\\site-packages\\scipy\\spatial\\distance.py:505: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1', '美女與野獸', 1.6192695806755202],\n",
      " ['4', '遠山戀人', 1.5851929310885704],\n",
      " ['3', '正義聯盟', 1.4546812367109343],\n",
      " ['5', '英雄傳說', 1.4096095531229911],\n",
      " ['16', '神鬼城市', 1.3952205212761872],\n",
      " ['2', '死亡筆記本', 1.3409252141755643],\n",
      " ['8', '小蘋果', 0.64399005491279393],\n",
      " ['9', '食物好吃', 0.50193247611417313],\n",
      " ['7', '可愛的威廉', 0.45059613577058788],\n",
      " ['10', '你好嗎', 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python35\\lib\\site-packages\\scipy\\spatial\\distance.py:505: RuntimeWarning: invalid value encountered in true_divide\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n"
     ]
    }
   ],
   "source": [
    "filename = \"task2_input.txt\"\n",
    "with open(filename, 'r', encoding=\"utf8\") as fp:\n",
    "    dat = fp.read()\n",
    "\n",
    "lines = [line.split('\\t') for line in dat.split('\\n') if line != '']\n",
    "\n",
    "for i, (idx, title) in enumerate(lines):\n",
    "    score = evaluation(title)\n",
    "    lines[i].append(score)\n",
    "\n",
    "title_sorted = sorted(lines, key=lambda x: x[2], reverse=True)\n",
    "pp.pprint(title_sorted)\n",
    "\n",
    "filename = \"task2_group7.txt\"\n",
    "with open(filename, 'w') as fp:\n",
    "    tmp = [ele[0] for ele in title_sorted]\n",
    "    fp.write('\\n'.join(tmp)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python35\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if sys.path[0] == '':\n",
      "c:\\python35\\lib\\site-packages\\ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "c:\\python35\\lib\\site-packages\\scipy\\spatial\\distance.py:505: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "war       Afanda.txt                                        騎士救援      1.359132  0    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python35\\lib\\site-packages\\scipy\\spatial\\distance.py:505: RuntimeWarning: invalid value encountered in true_divide\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action    Alien.txt                                         神鬼大夫      1.181068  10   \n",
      "drama     Baahubali 2_ The Conclusion.txt                   神鬼勞爾      0.812281  0    \n",
      "drama     Big Hero 6.txt                                    芥末佚事      0.876833  1    \n",
      "action    Bonnie and Clyde.txt                              女服遊戲      1.256678  0    \n",
      "war       Captain America_ Civil Wa.txt                     戰士重生      0.971355  9    \n",
      "action    Chugyeogja.txt                                    混蛋遊戲      1.452126  0    \n",
      "Empty!!  Dangal.txt\n",
      "super     Deadpool.txt                                      死侍聯盟      1.503168  0    \n",
      "action    Die Hard.txt                                      牛仔遊戲      1.403586  0    \n",
      "war       Dunkirk.txt                                       漲潮救援      1.156566  0    \n",
      "war       Edge of Tomorrow.txt                              戰士救援      1.278029  0    \n",
      "sci_fi    Guardians of the Galaxy Vol. 2.txt                星際地球      1.358349  0    \n",
      "sci_fi    Guardians of the Galaxy.txt                       星際地球      1.358349  0    \n",
      "action    Hea.txt                                           部隊遊戲      1.258448  2    \n",
      "drama     Hei'an qishi_ Liming shengq.txt                   城市佚事      0.995230  1    \n",
      "drama     Inception.txt                                     密碼佚事      0.922794  1    \n",
      "drama     Iron Man.txt                                      終極佚事      0.719549  7    \n",
      "horror    Logan.txt                                         鬼接線       0.990472  0    \n",
      "action    North by Northwe.txt                              神鬼大堂      1.181068  5    \n",
      "drama     Raiders of the Lost Ark.txt                       神鬼桿子      1.181068  0    \n",
      "drama     Ran.txt                                           神鬼大石      1.181068  0    \n",
      "drama     Rogue One.txt                                     神鬼帝國      1.107623  0    \n",
      "super     Rush.txt                                          英雄聯盟      1.416391  0    \n",
      "Empty!!  Serenity.txt\n",
      "war       Star Wars_ Episode VII - The Force Awaken.txt     武士救援      1.305930  0    \n",
      "drama     Taegukgi hwinalrimyeo.txt                         高地佚事      1.169756  2    \n",
      "drama     Terminator 2_ Judgment Day.txt                    終結者佚事     1.171980  2    \n",
      "drama     The Blues Brothe.txt                              神鬼搖滾      1.353738  0    \n",
      "action    The Bourne Ultimatum.txt                          玩命殺手      1.201748  9    \n",
      "drama     The Dark Knigh.txt                                神鬼城市      1.395221  0    \n",
      "drama     The General.txt                                   絕地佚事      0.877428  1    \n",
      "Empty!!  The Iron Gian.txt\n",
      "drama     The Wild Bunch.txt                                公司佚事      0.856618  1    \n",
      "action    Tropa de Elite 2_ O Inimigo Agora  Outro.txt      隊長遊戲      1.286421  2    \n",
      "action    Tropa de Elite.txt                                隊長遊戲      1.286421  2    \n",
      "crime     V for Vendetta.txt                                地下檔案      1.286190  2    \n",
      "war       Xingji zhengbazhan.txt                            地球救援      1.419649  0    \n",
      "drama     Ying xiong.txt                                    神鬼災禍      0.838118  0    \n",
      "drama     Aladdin.txt                                       神鬼魔毯      1.181068  0    \n",
      "drama     Almost Famou.txt                                  搖滾佚事      1.114165  2    \n",
      "drama     Back to the Future.txt                            惡魔佚事      1.173750  1    \n",
      "drama     Finding Nemo.txt                                  老爸佚事      0.853905  2    \n",
      "comedy    G.O.R.A.txt                                       美眉行不行     1.257280  0    \n",
      "horror    Hauru no ugoku shiro.txt                          絕命魔女      1.214603  0    \n",
      "war       How to Train Your Dragon.txt                      重生之子      1.109560  6    \n",
      "horror    Hunt for the Wilderpeople.txt                     失控終結者     1.212345  1    \n",
      "drama     Inside Ou.txt                                     神鬼歡樂      0.985666  1    \n",
      "sci_fi    Interstella.txt                                   星際引力      1.388141  0    \n",
      "drama     Into the Wild.txt                                 神鬼半山腰     0.851959  0    \n",
      "action    Jaw.txt                                           鉤子遊戲      1.261824  0    \n",
      "war       Lawrence of Arabia.txt                            開羅救援      1.239908  0    \n",
      "drama     Mononoke-hime.txt                                 武士佚事      1.172497  3    \n",
      "crime     Planet of the Ape.txt                             城市風雲      1.317094  2    \n",
      "horror    Shrek.txt                                         絕命騎士      1.242659  1    \n",
      "drama     Stand by Me.txt                                   謊話佚事      0.830424  4    \n",
      "war       The Bridge on the River Kwa.txt                   病號救援      1.138115  0    \n",
      "drama     The Grand Budapest Hotel.txt                      神鬼男孩      1.377060  0    \n",
      "drama     The Martian.txt                                   神鬼火星      1.391551  0    \n",
      "drama     The Message.txt                                   博士佚事      0.975648  1    \n",
      "drama     The Revenan.txt                                   神鬼隊長      1.354529  0    \n",
      "drama     The Treasure of the Sierra Madre.txt              強盜佚事      1.166110  2    \n",
      "sci_fi    Toy Story 2.txt                                   星際太空      1.439913  0    \n",
      "drama     U.txt                                             密碼佚事      0.922794  1    \n",
      "action    Zootopia.txt                                      兔子遊戲      1.400734  0    \n",
      "drama     Beauty and the Bea.txt                            月光佚事      1.171479  3    \n",
      "drama     Cinderella.txt                                    神鬼拳賽      0.844668  1    \n",
      "drama     Fantasia.txt                                      神鬼綠寶      1.498681  0    \n",
      "drama     Finding Dory.txt                                  神鬼大洋      1.181068  0    \n",
      "Empty!!  Ghost in the Shell.txt\n",
      "war       How to Train Your Dragon 2.txt                    重生之子      1.109560  6    \n",
      "horror    Howl's Moving Castle.txt                          失控魔女      1.205137  1    \n",
      "drama     Kubo and the Two String.txt                       武士佚事      1.172497  2    \n",
      "crime     Kung Fu Panda 2.txt                               陷阱風暴      1.435461  0    \n",
      "war       Kung Fu Panda.txt                                 功夫救援      1.289669  0    \n",
      "drama     L'illusionniste.txt                               神鬼國王      1.396108  0    \n",
      "sci_fi    Le Petit Prince.txt                               星際日落      1.389783  0    \n",
      "super     Megamind.txt                                      壞蛋聯盟      1.482251  0    \n",
      "horror    Moana.txt                                         絕命海底      1.187889  1    \n",
      "Empty!!  Mulan.txt\n",
      "crime     Ninja Scroll.txt                                  城市風雲      1.317094  1    \n",
      "drama     Paprika.txt                                       辣椒佚事      0.951878  1    \n",
      "war       Persepoli.txt                                     戰爭救援      1.392324  0    \n",
      "drama     Peter Pan.txt                                     神鬼滿手      0.836040  0    \n",
      "drama     Ponyo.txt                                         魔法佚事      0.952144  1    \n",
      "drama     Princess Mononoke.txt                             武士佚事      1.172497  3    \n",
      "drama     Ratatouille.txt                                   美食佚事      0.798550  6    \n",
      "drama     Shaun the Sheep Movie.txt                         月球佚事      1.176362  2    \n",
      "Empty!!  Sleeping Beauty.txt\n",
      "drama     Tangled.txt                                       神鬼公主      1.149395  0    \n",
      "super     The Book of Life.txt                              英雄聯盟      1.416391  0    \n",
      "drama     The Jungle Book.txt                               神鬼森林      1.368375  0    \n",
      "drama     The LEGO Batman Movie.txt                         神鬼星石      1.498157  0    \n",
      "drama     The Little Mermaid.txt                            海底佚事      1.172494  4    \n",
      "Empty!!  The Nightmare Before Christma.txt\n",
      "Empty!!  The Simpsons Movie.txt\n",
      "super     Wreck-It Ralph.txt                                英雄聯盟      1.416391  0    \n",
      "crime     3 Idio.txt                                        沉默者風暴     1.461677  0    \n",
      "drama     A Christmas Story.txt                             孩子佚事      0.837792  3    \n",
      "drama     Amarcord.txt                                      聖子佚事      0.735402  7    \n",
      "Empty!!  C.R.A.Z.Y.txt\n",
      "drama     Captain Fantastic.txt                             基督佚事      0.739591  6    \n",
      "Empty!!  Charade.txt\n",
      "drama     Crna macka, beli maco.txt                         神鬼手氣      0.853783  0    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drama     Dead Poets Society.txt                            俱樂部佚事     1.027244  1    \n",
      "Empty!!  In Bruge.txt\n",
      "drama     Jab We Me.txt                                     女孩佚事      0.846770  2    \n",
      "romance   Kal Ho Naa Ho.txt                                 真愛初戀      1.004945  0    \n",
      "drama     La Dolce Vita.txt                                 外套佚事      0.868729  1    \n",
      "drama     La La Land.txt                                    佚事之城      1.317270  3    \n",
      "drama     Life Is Beautiful.txt                             公主佚事      1.053171  3    \n",
      "drama     Manhattan.txt                                     公司佚事      0.856618  1    \n",
      "Empty!!  Mr. Smith Goes to Washington.txt\n",
      "Empty!!  My Sassy Girl.txt\n",
      "sci_fi    PK.txt                                            星際醉漢      1.043975  0    \n",
      "drama     Sing Stree.txt                                    音樂佚事      1.014978  2    \n",
      "war       The Big Lebowsk.txt                               安息日重生     0.789014  6    \n",
      "drama     The Intouchable.txt                               神鬼務實      0.808586  0    \n",
      "drama     The Kid.txt                                       空手道佚事     0.714537  5    \n",
      "drama     The Sting.txt                                     神鬼博士      1.363989  0    \n",
      "drama     The Truman Show.txt                               串謀佚事      0.775768  3    \n",
      "Empty!!  The Wolf of Wall Stree.txt\n",
      "Empty!!  Thor_ Ragnarok.txt\n",
      "drama     3-Iron.txt                                        神鬼修理工     0.851625  0    \n",
      "crime     A Clockwork Orange.txt                            罪惡風雲      1.384936  1    \n",
      "drama     Ah-ga-.txt                                        重考佚事      0.664905  4    \n",
      "drama     American History X.txt                            神鬼混蛋      0.960417  2    \n",
      "action    Breathle.txt                                      神鬼大堂      1.181068  5    \n",
      "drama     Catch Me If You Can.txt                           醫師佚事      0.898784  0    \n",
      "Empty!!  City of God.txt\n",
      "action    Contratiempo.txt                                  玩命男孩      1.200912  5    \n",
      "drama     Cool Hand Luke.txt                                神鬼隊長      1.354529  0    \n",
      "crime     Diabolique.txt                                    毒婦風雲      1.300552  1    \n",
      "drama     Dog Day Afternoon.txt                             電話佚事      0.999233  1    \n",
      "drama     Double Indemnity.txt                              丈夫佚事      0.884595  1    \n",
      "action    Elite Squad.txt                                   隊長遊戲      1.286421  2    \n",
      "action    Fargo.txt                                         屁屁遊戲      1.264154  0    \n",
      "romance   Gone Girl.txt                                     真愛爸媽      0.767193  0    \n",
      "drama     Goodfella.txt                                     聖誕佚事      1.167014  0    \n",
      "action    Infernal Affai.txt                                混蛋遊戲      1.452126  0    \n",
      "action    Nightcrawle.txt                                   大道遊戲      1.266450  0    \n",
      "Empty!!  No Country for Old Men.txt\n",
      "drama     On the Waterfron.txt                              神鬼碼頭      1.345358  0    \n",
      "drama     Once Were Warrio.txt                              勇士佚事      0.980613  1    \n",
      "war       Prisone.txt                                       混蛋救援      1.305989  0    \n",
      "drama     Pulp Fiction.txt                                  神鬼肚皮      0.845113  1    \n",
      "drama     Rope.txt                                          神鬼拳手      0.815269  3    \n",
      "drama     Scarface.txt                                      小妹佚事      0.772579  5    \n",
      "action    Se7en.txt                                         凶手遊戲      1.368036  0    \n",
      "action    Sin City.txt                                      神鬼大坑      1.181068  9    \n",
      "crime     Spotligh.txt                                      性侵風暴      1.262344  1    \n",
      "drama     Strangers on a Train.txt                          娃娃佚事      0.669407  7    \n",
      "action    Taxi Drive.txt                                    玩命司機      1.210521  5    \n",
      "action    The Departed.txt                                  玩命電話      1.118755  10   \n",
      "Empty!!  The Green Mile.txt\n",
      "drama     The Untouchable.txt                               神鬼務實      0.808586  0    \n",
      "crime     The Usual Suspec.txt                              碼頭風雲      1.584239  0    \n",
      "crime     True Romance.txt                                  混蛋檔案      1.303866  6    \n",
      "drama     Waa.txt                                           神鬼鐵匠      0.732845  1    \n",
      "comedy    American Beauty.txt                               伯父行不行     1.293721  0    \n",
      "drama     Andrei Rublev.txt                                 妻子佚事      0.908161  0    \n",
      "Empty!!  Apocalypse Now.txt\n",
      "drama     Bacheha-Ye aseman.txt                             拖鞋佚事      0.776176  7    \n",
      "war       Bravehea.txt                                      戰場重生      0.981452  10   \n",
      "Empty!!  Cidade de Deu.txt\n",
      "drama     Django Unchained.txt                              醫生佚事      1.163898  0    \n",
      "war       Full Metal Jacke.txt                              大兵救援      1.305695  0    \n",
      "action    Good Will Hunting.txt                             瑪麗遊戲      1.306669  0    \n",
      "drama     Ikiru.txt                                         神鬼俱樂部     1.375782  0    \n",
      "drama     It's a Wonderful Life.txt                         瑪麗佚事      1.172707  2    \n",
      "drama     Jagten.txt                                        神鬼牛仔      1.371526  0    \n",
      "drama     La vita  bella.txt                                公主佚事      1.053171  3    \n",
      "drama     Metropoli.txt                                     神鬼造物者     1.052980  0    \n",
      "drama     Nuovo Cinema Paradiso.txt                         神鬼公主      1.149395  0    \n",
      "war       Paths of Glory.txt                                部隊救援      1.257583  0    \n",
      "Empty!!  Saving Private Ryan.txt\n",
      "Empty!!  The Piani.txt\n",
      "drama     The Shining.txt                                   閃靈佚事      1.156755  1    \n",
      "Empty!!  300.txt\n",
      "horror    A Little Prince.txt                               絕命公主      1.195475  1    \n",
      "comedy    About Time.txt                                    全裸行不行     1.146930  0    \n",
      "war       Avata.txt                                         騎士救援      1.359132  0    \n",
      "drama     Being John Malkovich.txt                          博士佚事      0.975648  1    \n",
      "horror    Dead Man.txt                                      絕命海底      1.187889  1    \n",
      "crime     Death Note.txt                                    模木風暴      1.296026  2    \n",
      "drama     Harry Potter and the Goblet of Fire.txt           火焰杯佚事     1.015366  4    \n",
      "drama     Mary Poppin.txt                                   粉色佚事      0.726808  7    \n",
      "romance   Midnight in Pari.txt                              真愛作品      0.714207  0    \n",
      "sci_fi    Mr. Nobody.txt                                    星際之旅      1.379088  0    \n",
      "war       Star Wars_ The Force Awaken.txt                   武士救援      1.305930  0    \n",
      "drama     The Cabinet of Dr. Caliga.txt                     博士佚事      0.975648  2    \n",
      "drama     The Curious Case of Benjamin Button.txt           神鬼舞者      1.389344  0    \n",
      "drama     The Fall.txt                                      糖漿佚事      0.836369  2    \n",
      "drama     The Lord of the Rings_ The Two Towe.txt           神鬼森林      1.368375  0    \n",
      "horror    The Seventh Seal.txt                              絕命騎士      1.242659  1    \n",
      "war       Wonder Woman.txt                                  戰場重生      0.981452  10   \n",
      "drama     10 Cloverfield Lane.txt                           神鬼大富翁     0.922854  0    \n",
      "drama     28 Days Late.txt                                  心門佚事      0.771778  6    \n",
      "horror    A Nightmare on Elm Stree.txt                      鬼醒醒       0.840645  2    \n",
      "war       Blade.txt                                         殷破救援      1.142681  0    \n",
      "drama     Bubba Ho-Te.txt                                   神鬼貓王      1.492270  0    \n",
      "drama     Busanhaeng.txt                                    神鬼大叔      1.406635  0    \n",
      "super     Day of the Dead.txt                               英雄聯盟      1.416391  0    \n",
      "action    Don't Breathe.txt                                 神鬼賠償      1.373215  0    \n",
      "drama     Eraserhead.txt                                    神鬼嬰兒      1.394997  0    \n",
      "Empty!!  Evil Dead II.txt\n",
      "crime     Freak.txt                                         獄警風暴      1.304067  2    \n",
      "action    From Dusk Till Dawn.txt                           神鬼邊境      1.330811  0    \n",
      "drama     Get Ou.txt                                        柔道佚事      0.792173  2    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horror    Gremlin.txt                                       失控怪物      1.228125  0    \n",
      "crime     I Am Legend.txt                                   蝴蝶風雲      1.370370  0    \n",
      "sci_fi    I.txt                                             星際密碼      1.363598  0    \n",
      "crime     Invasion of the Body Snatche.txt                  脊髓炎風暴     1.296159  3    \n",
      "drama     Let the Right One In.txt                          頭豬佚事      0.847702  2    \n",
      "drama     Marty.txt                                         神鬼殉道者     0.856085  1    \n",
      "horror    Night of the Living Dead.txt                      絕命怪物      1.193925  2    \n",
      "crime     Only Lovers Left Alive.txt                        毒蠅風暴      1.280215  1    \n",
      "drama     Poltergei.txt                                     內褲佚事      0.864489  1    \n",
      "drama     Psycho.txt                                        倫敦佚事      0.959405  2    \n",
      "war       Re-Animato.txt                                    風暴重生      0.984047  8    \n",
      "drama     Rosemary's Baby.txt                               醫生佚事      1.163898  1    \n",
      "crime     Scream.txt                                        芳心風雲      1.464798  0    \n",
      "action    Sleepy Hollow.txt                                 騎士遊戲      1.377561  0    \n",
      "horror    Spli.txt                                          絕命怪物      1.193925  1    \n",
      "crime     Sweeney Todd_ The Demon Barber of Fleet Stree.txt 倫敦檔案      1.310640  0    \n",
      "drama     The Conjuring.txt                                 神鬼夢遊      1.385824  0    \n",
      "Empty!!  The Fly.txt\n",
      "drama     The Lost Boy.txt                                  電鋸佚事      0.885451  2    \n",
      "sci_fi    The Mi.txt                                        星際絕地      1.377234  0    \n",
      "drama     The Thing.txt                                     神鬼鼓手      1.335445  0    \n",
      "horror    Tremo.txt                                         鬼活捉       0.822133  2    \n",
      "drama     Tucker and Dale vs Evil.txt                       神鬼小屋      1.405368  0    \n",
      "horror    What We Do in the Shadow.txt                      絕命野獸      1.061377  1    \n",
      "horror    Zombieland.txt                                    絕命樂園      1.235529  0    \n",
      "romance   Before Midnigh.txt                                真愛生活      1.186857  0    \n",
      "romance   Before Sunse.txt                                  真愛生活      1.186857  0    \n",
      "drama     Blue Is the Warmest Colo.txt                      牡蠣佚事      0.807365  6    \n",
      "drama     Casablanca.txt                                    帝國佚事      1.037748  3    \n",
      "drama     Cast Away.txt                                     瑪麗佚事      1.172707  1    \n",
      "sci_fi    He.txt                                            星際黑洞      1.386848  0    \n",
      "drama     Head-On.txt                                       歡樂佚事      1.162403  0    \n",
      "drama     La leggenda del pianista sull_oceano.txt          音樂佚事      1.014978  3    \n",
      "romance   Once.txt                                          真愛生活      1.186857  0    \n",
      "drama     Rebecca.txt                                       神鬼批注      0.856180  1    \n",
      "drama     Sunrise.txt                                       神鬼大巴      1.181068  0    \n",
      "drama     The Arti.txt                                      神鬼電影      0.975506  0    \n",
      "drama     The Notebook.txt                                  神鬼隊長      1.354529  0    \n",
      "drama     The Perks of Being a Wallflowe.txt                瑪麗佚事      1.172707  1    \n",
      "war       The Remains of the Day.txt                        頓府救援      1.138755  0    \n",
      "drama     The Sound of Music.txt                            神鬼歌聲      1.094972  1    \n",
      "Empty!!  Titanic.txt\n",
      "drama     Veer-Zaara.txt                                    神鬼控方      0.915847  2    \n",
      "drama     Walk the Line.txt                                 神鬼內離      1.644739  0    \n",
      "drama     2001_ A Space Odyssey.txt                         神鬼博士      1.363989  0    \n",
      "drama     Arrival.txt                                       博士佚事      0.975648  1    \n",
      "drama     Blade Runne.txt                                   公司佚事      0.856618  3    \n",
      "crime     Brazil.txt                                        劇評風暴      1.288431  2    \n",
      "drama     District 9.txt                                    神鬼外星      0.877615  2    \n",
      "sci_fi    Donnie Darko.txt                                  星際時空      1.367904  0    \n",
      "drama     Gravity.txt                                       神鬼博士      1.363989  0    \n",
      "war       Mad Max_ Fury Road.txt                            戰爭救援      1.392324  0    \n",
      "sci_fi    Moon.txt                                          星際時空      1.367904  0    \n",
      "romance   Open Your Eye.txt                                 真愛分子      0.990171  0    \n",
      "drama     Stalke.txt                                        救援佚事      0.927560  2    \n",
      "war       Star Trek.txt                                     地球救援      1.419649  0    \n",
      "war       Star Trek_ Into Darkne.txt                        地球救援      1.419649  0    \n",
      "drama     Terminator 2.txt                                  神鬼終結者     1.189552  0    \n",
      "drama     The Day the Earth Stood Still.txt                 神鬼博士      1.363989  0    \n",
      "crime     Twelve Monkey.txt                                 猴子風暴      1.376864  1    \n",
      "war       A Very Long Engagemen.txt                         地帶救援      1.222074  0    \n",
      "romance   Downfall.txt                                      真愛帝國      1.047973  0    \n",
      "war       Fury.txt                                          戰爭救援      1.392324  0    \n",
      "war       Gallipol.txt                                      老弟救援      1.138433  0    \n",
      "war       Hacksaw Ridge.txt                                 行動重生      0.904029  10   \n",
      "drama     Hai.txt                                           神鬼姐妹      1.064885  0    \n",
      "drama     Lone Survivo.txt                                  麥芽佚事      0.815673  1    \n",
      "horror    Love and Death.txt                                絕命銀鬼      0.871392  2    \n",
      "drama     Lust, Caution.txt                                 重慶佚事      0.933272  1    \n",
      "war       No Man's Land.txt                                 戰爭救援      1.392324  0    \n",
      "war       Platoon.txt                                       混蛋救援      1.305989  0    \n",
      "drama     Spartacu.txt                                      神鬼蓋婭      0.858679  0    \n",
      "drama     The Book Thief.txt                                神鬼末日      0.884869  0    \n",
      "comedy    The Deer Hunte.txt                                杯酒行不行     1.198665  0    \n",
      "war       The Imitation Game.txt                            山大救援      1.399901  0    \n",
      "war       The Last of the Mohican.txt                       偉柏救援      1.136593  0    \n",
      "action    Where Eagles Dare.txt                             神鬼城堡      1.371113  0    \n",
      "crime     Zulu.txt                                          祖魯風暴      1.437569  0    \n"
     ]
    }
   ],
   "source": [
    "folder_ls = os.listdir(\"../11\")\n",
    "file_ls_ls = [os.listdir(\"../11/\"+folder) for folder in folder_ls]   # default: path=None\n",
    "# print([len(file_ls) for file_ls in file_ls_ls])\n",
    "\n",
    "filename_ls = []\n",
    "for i, folder in enumerate(folder_ls):\n",
    "    for filename in file_ls_ls[i]:\n",
    "        if filename in filename_ls:\n",
    "            continue\n",
    "        path = \"../11/\" + folder + \"/\" + filename\n",
    "        try:\n",
    "            title_score, genre = titleGen(path)\n",
    "            idx = titleSel(title_score, genre)\n",
    "            print(\"%-10s%-50s%-10s%-10f%-5d\" %(genre, filename, title_score[idx][0], title_score[idx][1], idx))\n",
    "        except:\n",
    "            print(\"Empty!! \", filename)\n",
    "        filename_ls.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
